{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting groq\n",
      "  Using cached groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from groq)\n",
      "  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from groq)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from groq)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting sniffio (from groq)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting typing-extensions<5,>=4.7 (from groq)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->groq)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->groq)\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->groq)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1.9.0->groq)\n",
      "  Using cached pydantic_core-2.20.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Using cached pydantic_core-2.20.1-cp312-none-win_amd64.whl (1.9 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing-extensions, sniffio, python-dotenv, idna, h11, distro, certifi, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, groq\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.4.0 certifi-2024.7.4 distro-1.9.0 groq-0.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.7 pydantic-2.8.2 pydantic-core-2.20.1 python-dotenv-1.0.1 sniffio-1.3.1 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models or lightweight language models, have gained significant attention in recent years due to their importance in various applications. Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Scalability**: Fast language models can process large amounts of text data quickly, making them suitable for applications that require real-time processing, such as chatbots, virtual assistants, and language translation systems.\n",
      "2. **Resource Efficiency**: Traditional language models are computationally expensive and require significant resources (e.g., memory, CPU, and GPU). Fast language models, on the other hand, are designed to be lightweight and can run on lower-end hardware, making them more accessible to a wider range of users.\n",
      "3. **Edge Computing**: With the increasing adoption of edge computing, fast language models can be deployed on edge devices, such as smartphones, smart home devices, and IoT devices, enabling real-time processing and reducing latency.\n",
      "4. **Real-time Applications**: Fast language models are essential for real-time applications, such as:\n",
      "\t* Speech recognition: Fast language models can recognize spoken language in real-time, enabling applications like voice assistants and speech-to-text systems.\n",
      "\t* Language translation: Fast language models can translate text in real-time, making them suitable for applications like instant messaging and online collaboration.\n",
      "\t* Sentiment analysis: Fast language models can analyze sentiment in real-time, enabling applications like customer service chatbots and social media monitoring.\n",
      "5. **Improved User Experience**: Fast language models can provide a better user experience by:\n",
      "\t* Reducing latency: Fast language models can respond quickly to user input, reducing the time it takes to process and respond to user queries.\n",
      "\t* Enabling conversational interfaces: Fast language models can power conversational interfaces, such as chatbots and voice assistants, making it easier for users to interact with devices and services.\n",
      "6. **Advancements in AI**: Fast language models can accelerate the development of artificial intelligence (AI) and machine learning (ML) applications by:\n",
      "\t* Enabling faster training: Fast language models can be trained quickly, allowing researchers to iterate and improve AI models faster.\n",
      "\t* Improving model accuracy: Fast language models can be used to fine-tune AI models, leading to improved accuracy and performance.\n",
      "7. **Cost-Effective**: Fast language models can reduce costs associated with:\n",
      "\t* Data storage: Fast language models require less storage space, reducing the need for expensive data storage solutions.\n",
      "\t* Compute resources: Fast language models can run on lower-end hardware, reducing the need for expensive compute resources.\n",
      "\n",
      "In summary, fast language models are crucial for various applications that require real-time processing, scalability, and resource efficiency. They can improve user experience, accelerate AI and ML development, and reduce costs associated with data storage and compute resources.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "client = Groq()\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain the importance of fast language models\"}\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
